{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This is  a research notebook to try to find correlation between hyperwave and volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'invalid': 'ignore', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "\n",
    "plotly.tools.set_credentials_file(username='davzucky', api_key='aZw7LRJOSDcPJyIk2G0U')\n",
    "# This is to avoid warning when dividing by zero\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the place where you setup the symbol and phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3DSystemsCorp ={\n",
    "    'name':'3D SYSTEMS CORP',\n",
    "    'symbol':'DDD',\n",
    "}\n",
    "\n",
    "\n",
    "data_Valeant = {\n",
    "    'name':'Baush health Company. Ex Valeant',\n",
    "    'symbol':'VRX',\n",
    "}\n",
    "\n",
    "data_Amazon = {\n",
    "    'name':'Amazon',\n",
    "    'symbol':'AMZN',\n",
    "}\n",
    "\n",
    "data_Netflix= {\n",
    "    'name':'Netflox',\n",
    "    'symbol':'NFLX',\n",
    "}\n",
    "\n",
    "data_Apple = {\n",
    "    'name':'Apple',\n",
    "    'symbol':'AAPL',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_setup = data_Apple\n",
    "name = company_setup ['name'] \n",
    "symbol = company_setup ['symbol']\n",
    "\n",
    "# constant used for other computation\n",
    "root_date = datetime(1800, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function \n",
    "This section contain helper function that are here to load and clean the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Url to fetch the data https://www.investopedia.com/markets/api/partial/historical/?Symbol=AAPL&Type=Historical+Prices&Timeframe=Weekly&StartDate=Jan+01%2C+1900\n",
      "fetching data for AAPL on Weekly...\n"
     ]
    }
   ],
   "source": [
    "def get_raw_historical_data(symbol, timeframe='daily'):\n",
    "    url_symbol = \"https://www.investopedia.com/markets/api/partial/historical/?Symbol={}&Type=Historical+Prices&Timeframe={}&StartDate=Jan+01%2C+1900\".format(symbol, timeframe)\n",
    "    print(\"Url to fetch the data {}\".format(url_symbol))\n",
    "    print(\"fetching data for {} on {}...\".format(symbol, timeframe))\n",
    "    df_list = pd.read_html(url_symbol, header=0, parse_dates=True)\n",
    "    df_price = df_list[0].dropna()\n",
    "    return df_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that allow to calculate the weekid from a start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_weeks(row, base_date = root_date):\n",
    "    return int((row[\"date\"]-base_date).days/7)\n",
    "\n",
    "def clean_raw_market_data(df):\n",
    "    df.loc[:,('date')] = pd.to_datetime(df.loc[:,('Date')])\n",
    "    df = df.rename(columns={'Adj. Close':'close'})\n",
    "    df['is_price_closing_up'] = df.close > df.close.shift()\n",
    "    df['weekId'] = df.apply (lambda row: get_nb_weeks (row),axis=1)\n",
    "    return df.sort_values(by=\"date\")\n",
    "\n",
    "def get_weekId_max_price(df):\n",
    "    return df.ix[ df['close'].argmax()][\"weekId\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekId_cartesian_product(df):\n",
    "    df_from = df.loc[:,('weekId',\"close\")].rename(index=str, columns={\"weekId\": \"weekId_from\", \"close\": \"close_from\"})\n",
    "    df_to = df.loc[:,('weekId',\"close\")].rename(index=str, columns={\"weekId\": \"weekId_to\", \"close\": \"close_to\"})\n",
    "    df_cartesian = df_from.assign(foo=1).merge(df_to.assign(foo=1)).drop('foo', 1)\n",
    "\n",
    "    return df_cartesian [(df_cartesian .weekId_from < df_cartesian .weekId_to)]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here we start fetching the data\n",
    "Above was only about setting up some basic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Url to fetch the data https://www.investopedia.com/markets/api/partial/historical/?Symbol=AAPL&Type=Historical+Prices&Timeframe=Weekly&StartDate=Jan+01%2C+1900\n",
      "fetching data for AAPL on Weekly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:12: DeprecationWarning:\n",
      "\n",
      "\n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_daily_price_raw = get_raw_historical_data(symbol, 'Daily')\n",
    "df_weekly_price_raw = get_raw_historical_data(symbol, 'Weekly')\n",
    "\n",
    "df_weekly_price = clean_raw_market_data(df_weekly_price_raw)\n",
    "\n",
    "max_price_weekId = get_weekId_max_price(df_weekly_price)\n",
    "df_weekly_price_until_max = df_weekly_price [(df_weekly_price.weekId < max_price_weekId)]\n",
    "weekId_close_from_to = get_weekId_cartesian_product(df_weekly_price_until_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_slope_and_origine(df, x1_col_name = 'x1', \\\n",
    "                               y1_col_name = 'y1', \\\n",
    "                               x2_col_name = 'x2', \\\n",
    "                               y2_col_name = 'y2', \\\n",
    "                               m_col_name = 'm', \\\n",
    "                               b_col_name = 'b'):\n",
    "    df[m_col_name] = (df[y1_col_name] - df[y2_col_name]) / (df[x1_col_name] - df[x2_col_name])\n",
    "    df[b_col_name] = df[y1_col_name] - (df[x1_col_name] * df[m_col_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = ConvexHull(df_weekly_price_until_max[['weekId', 'close']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date    Open    High     Low   close       Volume       date  \\\n",
      "1497  Jan 05, 1990    1.12    1.13    1.09    1.12  123379200.0 1990-01-05   \n",
      "1496  Jan 12, 1990    1.01    1.03    1.00    1.02  172200000.0 1990-01-12   \n",
      "1495  Jan 19, 1990    1.00    1.02    0.99    1.01  265596800.0 1990-01-19   \n",
      "1494  Jan 26, 1990    1.01    1.01    0.95    0.97  181776000.0 1990-01-26   \n",
      "1493  Feb 02, 1990    0.98    1.03    0.98    1.01  118966400.0 1990-02-02   \n",
      "1492  Feb 09, 1990    0.99    1.02    0.98    1.01  168123200.0 1990-02-09   \n",
      "1491  Feb 16, 1990    1.02    1.02    1.00    1.00  127579200.0 1990-02-16   \n",
      "1490  Feb 23, 1990    0.97    0.99    0.97    0.99  150516800.0 1990-02-23   \n",
      "1489  Mar 02, 1990    0.99    1.03    0.99    1.00  105313600.0 1990-03-02   \n",
      "1488  Mar 09, 1990    1.09    1.11    1.08    1.09  230966400.0 1990-03-09   \n",
      "1487  Mar 16, 1990    1.19    1.21    1.16    1.19  645187200.0 1990-03-16   \n",
      "1486  Mar 23, 1990    1.22    1.28    1.22    1.25  228345600.0 1990-03-23   \n",
      "1485  Mar 30, 1990    1.19    1.22    1.19    1.19  223619200.0 1990-03-30   \n",
      "1484  Apr 06, 1990    1.19    1.22    1.18    1.18  118596800.0 1990-04-06   \n",
      "1483  Apr 12, 1990    1.28    1.31    1.26    1.28  211870400.0 1990-04-12   \n",
      "1482  Apr 20, 1990    1.21    1.23    1.18    1.19  324060800.0 1990-04-20   \n",
      "1481  Apr 27, 1990    1.16    1.17    1.15    1.16  117006400.0 1990-04-27   \n",
      "1480  May 04, 1990    1.19    1.21    1.16    1.19  169769600.0 1990-05-04   \n",
      "1479  May 11, 1990    1.23    1.27    1.21    1.26  215353600.0 1990-05-11   \n",
      "1478  May 18, 1990    1.22    1.23    1.17    1.18  258944000.0 1990-05-18   \n",
      "1477  May 25, 1990    1.18    1.21    1.16    1.19  323747200.0 1990-05-25   \n",
      "1476  Jun 01, 1990    1.23    1.25    1.21    1.21  157483200.0 1990-06-01   \n",
      "1475  Jun 08, 1990    1.15    1.15    1.12    1.14  333950400.0 1990-06-08   \n",
      "1474  Jun 15, 1990    1.18    1.19    1.16    1.18  144580800.0 1990-06-15   \n",
      "1473  Jun 22, 1990    1.25    1.27    1.23    1.23  284323200.0 1990-06-22   \n",
      "1472  Jun 29, 1990    1.28    1.34    1.27    1.33  325416000.0 1990-06-29   \n",
      "1471  Jul 06, 1990    1.29    1.34    1.29    1.33  209473600.0 1990-07-06   \n",
      "1470  Jul 13, 1990    1.41    1.42    1.39    1.39  231123200.0 1990-07-13   \n",
      "1469  Jul 20, 1990    1.25    1.26    1.21    1.22  192024000.0 1990-07-20   \n",
      "1468  Jul 27, 1990    1.23    1.24    1.20    1.23   62720000.0 1990-07-27   \n",
      "...            ...     ...     ...     ...     ...          ...        ...   \n",
      "31    Jan 19, 2018  176.58  177.54  175.40  176.43   32425067.0 2018-01-19   \n",
      "30    Jan 26, 2018  170.05  170.05  168.13  169.56   39143011.0 2018-01-26   \n",
      "29    Feb 02, 2018  164.12  164.91  158.28  158.68   86593825.0 2018-02-02   \n",
      "28    Feb 09, 2018  155.92  156.73  149.14  155.26   70672608.0 2018-02-09   \n",
      "27    Feb 16, 2018  171.10  173.54  170.51  171.17   40176091.0 2018-02-16   \n",
      "26    Feb 23, 2018  172.40  174.36  172.27  174.21   33812360.0 2018-02-23   \n",
      "25    Mar 02, 2018  171.53  175.01  171.19  174.92   38453950.0 2018-03-02   \n",
      "24    Mar 09, 2018  176.66  178.68  176.09  178.66   32185162.0 2018-03-09   \n",
      "23    Mar 16, 2018  177.34  177.81  176.32  176.72   39404688.0 2018-03-16   \n",
      "22    Mar 23, 2018  167.16  168.68  163.73  163.73   41028784.0 2018-03-23   \n",
      "21    Mar 29, 2018  166.58  170.49  165.68  166.55   38398505.0 2018-03-29   \n",
      "20    Apr 06, 2018  169.72  171.22  166.97  167.15   35005290.0 2018-04-06   \n",
      "19    Apr 13, 2018  173.50  174.55  172.58  173.45   25124255.0 2018-04-13   \n",
      "18    Apr 20, 2018  169.35  169.96  164.22  164.51   65491140.0 2018-04-20   \n",
      "17    Apr 27, 2018  162.80  163.13  159.45  161.13   35655839.0 2018-04-27   \n",
      "16    May 04, 2018  176.94  182.90  176.87  182.48   56201317.0 2018-05-04   \n",
      "15    May 11, 2018  188.83  189.40  186.79  187.93   26212221.0 2018-05-11   \n",
      "14    May 18, 2018  186.54  187.15  185.48  185.66   18297728.0 2018-05-18   \n",
      "13    May 25, 2018  187.57  188.99  186.99  187.92   17460963.0 2018-05-25   \n",
      "12    Jun 01, 2018  187.33  189.60  187.09  189.58   23442510.0 2018-06-01   \n",
      "11    Jun 08, 2018  190.50  191.33  189.11  191.03   26656799.0 2018-06-08   \n",
      "10    Jun 15, 2018  189.37  189.50  187.60  188.18   61719160.0 2018-06-15   \n",
      "9     Jun 22, 2018  185.47  185.50  184.05  184.27   27200447.0 2018-06-22   \n",
      "8     Jun 29, 2018  185.64  186.54  182.27  184.46   22737666.0 2018-06-29   \n",
      "7     Jul 06, 2018  184.77  187.78  184.55  187.31   17485245.0 2018-07-06   \n",
      "6     Jul 13, 2018  190.41  191.17  190.23  190.66   12519792.0 2018-07-13   \n",
      "5     Jul 20, 2018  191.11  191.76  189.51  190.77   20706042.0 2018-07-20   \n",
      "4     Jul 27, 2018  194.31  194.51  189.44  190.31   24023972.0 2018-07-27   \n",
      "3     Aug 03, 2018  206.31  208.01  204.76  207.26   33447396.0 2018-08-03   \n",
      "2     Aug 10, 2018  207.36  209.10  206.67  207.53   24611202.0 2018-08-10   \n",
      "\n",
      "      is_price_closing_up  weekId  \n",
      "1497                 True    9914  \n",
      "1496                 True    9915  \n",
      "1495                 True    9916  \n",
      "1494                False    9917  \n",
      "1493                False    9918  \n",
      "1492                 True    9919  \n",
      "1491                 True    9920  \n",
      "1490                False    9921  \n",
      "1489                False    9922  \n",
      "1488                False    9923  \n",
      "1487                False    9924  \n",
      "1486                 True    9925  \n",
      "1485                 True    9926  \n",
      "1484                False    9927  \n",
      "1483                 True    9928  \n",
      "1482                 True    9929  \n",
      "1481                False    9930  \n",
      "1480                False    9931  \n",
      "1479                 True    9932  \n",
      "1478                False    9933  \n",
      "1477                False    9934  \n",
      "1476                 True    9935  \n",
      "1475                False    9936  \n",
      "1474                False    9937  \n",
      "1473                False    9938  \n",
      "1472                False    9939  \n",
      "1471                False    9940  \n",
      "1470                 True    9941  \n",
      "1469                False    9942  \n",
      "1468                False    9943  \n",
      "...                   ...     ...  \n",
      "31                   True   11377  \n",
      "30                   True   11378  \n",
      "29                   True   11379  \n",
      "28                  False   11380  \n",
      "27                  False   11381  \n",
      "26                  False   11382  \n",
      "25                  False   11383  \n",
      "24                   True   11384  \n",
      "23                   True   11385  \n",
      "22                  False   11386  \n",
      "21                  False   11387  \n",
      "20                  False   11388  \n",
      "19                   True   11389  \n",
      "18                   True   11390  \n",
      "17                  False   11391  \n",
      "16                  False   11392  \n",
      "15                   True   11393  \n",
      "14                  False   11394  \n",
      "13                  False   11395  \n",
      "12                  False   11396  \n",
      "11                   True   11397  \n",
      "10                   True   11398  \n",
      "9                   False   11399  \n",
      "8                   False   11400  \n",
      "7                   False   11401  \n",
      "6                   False   11402  \n",
      "5                    True   11403  \n",
      "4                   False   11404  \n",
      "3                   False   11405  \n",
      "2                   False   11406  \n",
      "\n",
      "[1493 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_weekly_price_until_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~davzucky/12.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "x = df_weekly_price_until_max['weekId'].values\n",
    "y =  df_weekly_price_until_max['close'].values\n",
    "trace0 = go.Scatter(\n",
    "    x = x,\n",
    "    y = y,\n",
    "    mode = 'lines',\n",
    "    name = 'lines'\n",
    ")\n",
    "\n",
    "layout = {\n",
    "#     'xaxis': {\n",
    "#         'range': [0, 7]\n",
    "#     },\n",
    "#     'yaxis': {\n",
    "#         'range': [0, 2.5]\n",
    "#     },\n",
    "    'shapes': [{\n",
    "            'type': 'line',\n",
    "            'x0': x[pair[0]],\n",
    "            'y0': y[pair[0]],\n",
    "            'x1': x[pair[1]],\n",
    "            'y1': y[pair[1]],\n",
    "            'line': {\n",
    "                'color': 'rgb(55, 128, 191)',\n",
    "                'width': 3,\n",
    "            }\n",
    "        } for pair in hull.simplices\n",
    "        # Line Vertical\n",
    "        ]\n",
    "}\n",
    "data = [trace0]\n",
    "\n",
    "# py.iplot(data, filename='line-mode')\n",
    "fig = {\n",
    "    'data': data,\n",
    "    'layout': layout,\n",
    "}\n",
    "\n",
    "py.iplot(fig, filename='shapes-lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1492,    0],\n",
       "       [1000, 1225],\n",
       "       [   3,   39],\n",
       "       [ 391,  416],\n",
       "       [ 391,   39],\n",
       "       [1375, 1225],\n",
       "       [1375, 1381],\n",
       "       [   1,    0],\n",
       "       [   1,    3],\n",
       "       [1490, 1492],\n",
       "       [1490, 1477],\n",
       "       [1404, 1381],\n",
       "       [1404, 1477],\n",
       "       [ 693,  416],\n",
       "       [ 693,  728],\n",
       "       [ 993, 1000],\n",
       "       [ 993,  763],\n",
       "       [ 761,  763],\n",
       "       [ 737,  728],\n",
       "       [ 737,  761]], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hull.simplices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_line_slope(row):\n",
    "#     return (row.close_from - row.close_to) / (row.weekId_from - row.weekId_to)\n",
    "\n",
    "# weekId_close_from_to['slope'] = weekId_close_from_to.apply (lambda row: get_line_slope(row),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# weekId_close_from_to\n",
    "\n",
    "# # m = -0.110000\n",
    "# # b = 1092.930000\n",
    "# # m = 15.82\n",
    "# # b = -177675.62\n",
    "# def is_phase_below(m, b):\n",
    "# #     m = row.m\n",
    "# #     b = row.b\n",
    "#     df = df_weekly_price\n",
    "#     df_weekly_close = df[[\"weekId\", \"close\"]]\n",
    "#     df_weekly_close['ln_y'] = (df_weekly_close.weekId * m) + b\n",
    "#     df_weekly_close['is_below'] = df_weekly_close.ln_y.le(df_weekly_close.close) | np.isclose(df_weekly_close['ln_y'], df_weekly_close['close'])\n",
    "#     return df_weekly_close['is_below'].all()\n",
    "\n",
    "\n",
    "# weekId_close_from_to['is_below'] = weekId_close_from_to.apply (lambda row: is_phase_below(row, df_weekly_price),axis=1)\n",
    "# is_phase_below()\n",
    "\n",
    "# weekId_close_from_to['r'] = weekId_close_from_to(weekId_close_from_to['m'], weekId_close_from_to['b'] )\n",
    "\n",
    "# weekId_close_from_to\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "\n",
    "\n",
    "# df = df_weekly_price_until_max[:15].rename(columns={'weekId':'x', 'close': 'y'})\n",
    "\n",
    "\n",
    "# data = {'x':[1,2,3,4],'y':[5,6,10,12]}\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "# calculate m and b from y = mx = b\n",
    "# df_m = (df['y'].values - df['y'].values[:, None]) / (df['x'].values - df['x'].values[:, None])\n",
    "# df_b = df['y'].values - (df['x'].values * df_m)\n",
    "\n",
    "\n",
    "# import itertools\n",
    "# nb_partition = int((df['x'].values.shape[0] / 10)) + 1\n",
    "# x_values_split = np.array_split(df['x'].values, nb_partition) \n",
    "# y_values_split = np.array_split(df['y'].values, nb_partition)              \n",
    "\n",
    "\n",
    "# def get_y_values(x_value, m, b):\n",
    "#     x_lenght = x_values.shape[0]\n",
    "#     cube_shape = (x_lenght, 1, 1)\n",
    "#     x_cube = np.reshape(x_values, cube_shape)\n",
    "    \n",
    "#     return (x_cube * m) + b \n",
    "\n",
    "# def get_is_line_above_close(x_values, y_values, m, b):\n",
    "#     y_lenght = y_values.shape[0]\n",
    "#     cube_shape = (y_lenght, 1, 1)\n",
    "    \n",
    "#     y_cube = np.reshape(y_values, cube_shape)\n",
    "#     return get_y_values(x_values,m, b) < y_cube\n",
    "\n",
    "    \n",
    "# result = [get_y_values(x_values, df_m, df_b) for (x_values, y_values) in itertools.zip_longest(x_values_split, y_values_split )]\n",
    "#     x_lenght = x_values.shape[0]\n",
    "#     cube_shape = (x_lenght, 1, 1)\n",
    "    \n",
    "#     x_cube = np.reshape(x_values, cube_shape)\n",
    "#     y_cube = np.reshape(y_values, cube_shape)\n",
    "#     cube_y_value_calculated =  (x_cube * df_m) + df_b \n",
    "\n",
    "# x_values = x_values_split[0]\n",
    "# y_values = y_values_split[0]              \n",
    "# x_lenght = x_values.shape[0]\n",
    "# cube_shape = (x_lenght, 1, 1)\n",
    "\n",
    "# x_cube = np.reshape(x_values, cube_shape)\n",
    "# y_cube = np.reshape(y_values, cube_shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
